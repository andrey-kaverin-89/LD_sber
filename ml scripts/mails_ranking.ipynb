{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T10:51:05.930895Z",
     "start_time": "2020-11-28T10:51:05.926724Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from pymystem3 import Mystem\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T10:34:19.156423Z",
     "start_time": "2020-11-28T10:34:19.149622Z"
    }
   },
   "outputs": [],
   "source": [
    "def stemming(tokens: list) -> pd.Series:\n",
    "    stem = Mystem()\n",
    "    tokens = [word_tokenize(\"\".join(stem.lemmatize(sentence))) for sentence in tokens]\n",
    "    tokens = [[word for word in sentence if len(word) > 2] for sentence in tokens]\n",
    "#     tokens = [\n",
    "#         [\n",
    "#             word\n",
    "#             for word in sentence\n",
    "#             if morph.parse(word)[0].tag.POS == \"NOUN\"\n",
    "#             or morph.parse(word)[0].tag.POS == \"ADJF\"\n",
    "#         ]\n",
    "#         for sentence in tokens\n",
    "#     ]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T10:34:19.566497Z",
     "start_time": "2020-11-28T10:34:19.561824Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_stopwords(text: pd.Series) -> pd.Series:\n",
    "    result = [\n",
    "        [word for word in sentence if word not in ru_stopwords and word != \" \"]\n",
    "        for sentence in text\n",
    "    ]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T10:34:20.060500Z",
     "start_time": "2020-11-28T10:34:20.054291Z"
    }
   },
   "outputs": [],
   "source": [
    "ru_stopwords = stopwords.words(\"russian\")\n",
    "final_df = pd.read_csv('dataset.csv')\n",
    "\n",
    "final_df['clean_text'] = final_df.text.apply(lambda x: re.sub('[0-9]+', '', x))\n",
    "final_df['clean_text'] = final_df.clean_text.apply(lambda x: re.sub('[^а-яА-Я]+', ' ', x))\n",
    "final_df['clean_text'] = final_df.clean_text.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T10:53:37.095019Z",
     "start_time": "2020-11-28T10:52:11.934821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 18s, sys: 3.04 s, total: 1min 21s\n",
      "Wall time: 3min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lemmatized_tokens = stemming(final_df.clean_text)\n",
    "lemmatized_tokens = check_stopwords(lemmatized_tokens)\n",
    "final_df['clean_text'] = lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T10:54:47.076792Z",
     "start_time": "2020-11-28T10:54:45.732666Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=lemmatized_tokens, size=50, window=10, min_count=3, workers=-1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T10:55:42.042284Z",
     "start_time": "2020-11-28T10:55:42.035114Z"
    }
   },
   "outputs": [],
   "source": [
    "outbox_df = pd.DataFrame(final_df[final_df['type'] == 'outbox']).reset_index(drop=True)\n",
    "outbox_vectors = []\n",
    "\n",
    "for text in outbox_df.clean_text:\n",
    "    tmp = []\n",
    "    for word in text:\n",
    "        try:\n",
    "            tmp.append(model.wv.get_vector(word))\n",
    "        except:\n",
    "#             print(word)\n",
    "            pass\n",
    "    if len(tmp) != 0:\n",
    "        outbox_vectors.append(sum(tmp) / len(tmp))\n",
    "    else:\n",
    "\n",
    "        outbox_vectors.append([None for _ in range(50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T10:40:54.640438Z",
     "start_time": "2020-11-28T10:40:54.632526Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_emails = []\n",
    "for i in outbox_df['to']:\n",
    "    try:\n",
    "        clean_emails.append(re.search(r'[0-9A-Za-z\\.-]+@[\\.a-z]+', i).group(0))\n",
    "    except AttributeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T10:41:46.290367Z",
     "start_time": "2020-11-28T10:41:46.284762Z"
    }
   },
   "outputs": [],
   "source": [
    "outbox_df['to_clean'] = clean_emails\n",
    "modelling = pd.DataFrame(outbox_vectors, index=outbox_df.index)\n",
    "modelling['email'] = outbox_df.to_clean\n",
    "to_drop = modelling[modelling[0].isnull()].index\n",
    "modelling = modelling.drop(index = to_drop ).reset_index(drop=True)\n",
    "outbox_df = outbox_df.drop(index = to_drop ).reset_index(drop=True)\n",
    "X = modelling.copy()#.drop(columns=['email'])\n",
    "clean_emails = pd.DataFrame({'emails': clean_emails})\n",
    "test_index = X[X.email.isin(clean_emails.emails.value_counts()[:3].keys().tolist())].index\n",
    "random.seed(65)\n",
    "test_index = random.sample(list(test_index), k=30)\n",
    "X.drop(columns=['email'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T10:42:48.556579Z",
     "start_time": "2020-11-28T10:42:48.549751Z"
    }
   },
   "outputs": [],
   "source": [
    "test = X.loc[test_index, :]\n",
    "train = X[~X.index.isin(test_index)]\n",
    "neigh = NearestNeighbors(n_neighbors=5, radius=0.01)\n",
    "neigh.fit(train)\n",
    "preds = neigh.kneighbors(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T10:11:39.476879Z",
     "start_time": "2020-11-28T10:11:39.468668Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_rad = []\n",
    "filtered_ind = []\n",
    "\n",
    "for row in range(len(preds[0])):\n",
    "    tmp = []\n",
    "    tmp1 = []\n",
    "    for ind in range(len(preds[0][row])):\n",
    "        if preds[0][row][ind] < 0.11:\n",
    "            tmp.append(preds[0][row][ind])\n",
    "            tmp1.append(preds[1][row][ind])\n",
    "    filtered_rad.append(tmp)\n",
    "    filtered_ind.append(tmp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i, ind in enumerate(test.index):\n",
    "    email = outbox_df.at[ind, 'to_clean']\n",
    "    if email in modelling.loc[filtered_ind[i], 'email'].tolist():\n",
    "        acc.append(1)\n",
    "    else:\n",
    "        acc.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(acc)/len(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:46<00:00,  2.14it/s]\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for rand in tqdm(range(100)):     \n",
    "    outbox_df = pd.DataFrame(final_df[final_df['type'] == 'outbox']).reset_index(drop=True)\n",
    "    outbox_vectors = []\n",
    "\n",
    "    for text in outbox_df.clean_text:\n",
    "        tmp = []\n",
    "        for word in text:\n",
    "            try:\n",
    "                tmp.append(model.wv.get_vector(word))\n",
    "            except:\n",
    "    #             print(word)\n",
    "                pass\n",
    "        if len(tmp) != 0:\n",
    "            outbox_vectors.append(sum(tmp) / len(tmp))\n",
    "        else:\n",
    "            outbox_vectors.append([None for _ in range(50)])\n",
    "    clean_emails = []\n",
    "    for i in outbox_df['to']:\n",
    "        try:\n",
    "            clean_emails.append(re.search(r'[0-9A-Za-z\\.-]+@[\\.a-z]+', i).group(0))\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    outbox_df['to_clean'] = clean_emails\n",
    "    modelling = pd.DataFrame(outbox_vectors, index=outbox_df.index)\n",
    "    modelling['email'] = outbox_df.to_clean\n",
    "    to_drop = modelling[modelling[0].isnull()].index\n",
    "    modelling = modelling.drop(index = to_drop ).reset_index(drop=True)\n",
    "    outbox_df = outbox_df.drop(index = to_drop ).reset_index(drop=True)\n",
    "    X = modelling.copy()#.drop(columns=['email'])\n",
    "    clean_emails = pd.DataFrame({'emails': clean_emails})\n",
    "    test_index = X[X.email.isin(clean_emails.emails.value_counts()[:3].keys().tolist())].index\n",
    "    random.seed(rand)\n",
    "    test_index = random.sample(list(test_index), k=30)\n",
    "    X.drop(columns=['email'], inplace=True)\n",
    "    test = X.loc[test_index, :]\n",
    "    train = X[~X.index.isin(test_index)]\n",
    "    neigh = NearestNeighbors(n_neighbors=10, radius=0.01)\n",
    "    neigh.fit(train)\n",
    "    preds = neigh.kneighbors(test)\n",
    "    filtered_rad = []\n",
    "    filtered_ind = []\n",
    "\n",
    "    for row in range(len(preds[0])):\n",
    "        tmp = []\n",
    "        tmp1 = []\n",
    "        for ind in range(len(preds[0][row])):\n",
    "            if preds[0][row][ind] < 0.11:\n",
    "                tmp.append(preds[0][row][ind])\n",
    "                tmp1.append(preds[1][row][ind])\n",
    "        filtered_rad.append(tmp)\n",
    "        filtered_ind.append(tmp1)\n",
    "    acc = []\n",
    "    for i, ind in enumerate(test.index):\n",
    "        email = outbox_df.at[ind, 'to_clean']\n",
    "        if email in modelling.loc[filtered_ind[i], 'email'].tolist():\n",
    "            acc.append(1)\n",
    "        else:\n",
    "            acc.append(0)\n",
    "    res.append(sum(acc)/len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelling.to_csv('modelling_dots.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Это финал цифрового прорыва, сроки спасибо с уважением'\n",
    "s = pd.Series(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Это финал цифрового прорыва, сроки спасибо с у...\n",
       "dtype: object"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_pr(text):\n",
    "    s = pd.Series(text)\n",
    "    s = s.apply(lambda x: re.sub('[0-9]+', '', x))\n",
    "    s = s.apply(lambda x: re.sub('[^а-яА-Я]+', ' ', x))\n",
    "    s = s.apply(lambda x: x.lower())\n",
    "    s = stemming(s)\n",
    "    s = check_stopwords(s)\n",
    "    return ' '.join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dots(text):\n",
    "    tmp = []\n",
    "    for word in text:\n",
    "        try:\n",
    "            tmp.append(model.wv.get_vector(word))\n",
    "        except:\n",
    "#             print(word)\n",
    "            pass\n",
    "    if len(tmp) != 0:\n",
    "        outbox_vectors.append(sum(tmp) / len(tmp))\n",
    "    else:\n",
    "\n",
    "        outbox_vectors.append([None for _ in range(50)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
